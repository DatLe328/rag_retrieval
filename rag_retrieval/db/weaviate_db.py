import weaviate
import weaviate.classes as wvc
from weaviate.classes.config import Configure, Property, DataType
from weaviate.classes.query import MetadataQuery
from weaviate.classes.init import AdditionalConfig
from typing import List, Dict, Optional, Any
from datetime import datetime


class WeaviateManager:
    def __init__(self, host="localhost", http_port=8080, grpc_port=50051, embedder=None):
        self.host = host
        self.http_port = http_port
        self.grpc_port = grpc_port
        self.embedder = embedder
        self.client = None

    def __enter__(self):
        try:
            self.client = weaviate.connect_to_custom(
                http_host=self.host,
                http_port=self.http_port,
                http_secure=False,
                grpc_host=self.host,
                grpc_port=self.grpc_port,
                grpc_secure=False,
                additional_config=AdditionalConfig(timeout=(10, 60)),
            )
            return self
        except Exception as e:
            raise ConnectionError(f"KhÃ´ng thá»ƒ káº¿t ná»‘i tá»›i Weaviate: {e}")

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.client:
            self.client.close()

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.client:
            self.client.close()

    def create_collection(self, name: str, properties: List[Property], vector_config: Any = None, force_recreate: bool = False):
        """Táº¡o collection, máº·c Ä‘á»‹nh dÃ¹ng self_provided vectors."""
        if force_recreate and self.client.collections.exists(name):
            self.client.collections.delete(name)

        if not self.client.collections.exists(name):
            if vector_config is None:
                vector_config = Configure.Vectors.self_provided(
                    vector_index_config=Configure.VectorIndex.hnsw(
                        distance_metric=wvc.config.VectorDistances.COSINE
                    )
                )
            self.client.collections.create(name=name, properties=properties, vector_config=vector_config)

    def add(
        self,
        collection_name: str,
        title: str,
        abstract: str,
        keywords: list[str],
        text: str,
        created_date: datetime,
        vector: Optional[List[float]] = None,
    ):
        """ThÃªm tÃ i liá»‡u â€” tá»± Ä‘á»™ng sinh vector náº¿u chÆ°a cÃ³."""
        if vector is None:
            if not self.embedder:
                raise ValueError("KhÃ´ng cÃ³ embedder Ä‘á»ƒ sinh vector.")
            vector = self.embedder.get_embedding(title)

        collection = self.client.collections.get(collection_name)
        collection.data.insert(
            properties={
                "title": title,
                "abstract": abstract,
                "keywords": keywords,
                "text": text,
                "created_date": created_date,
            },
            vector=vector,
        )

    def search(
        self,
        collection_name: str,
        query: Any,
        search_type: str = "vector",
        limit: int = 5,
        properties: List[str] = ["title", "abstract", "keywords", "text"]
    ) -> List[Dict]:
        """Tráº£ vá» list gá»“m uuid, properties, score (cÃ ng cao cÃ ng tá»‘t)."""
        collection = self.client.collections.get(collection_name)

        # âœ… Náº¿u lÃ  vector search, mÃ  query lÃ  text â†’ tá»± embed
        if search_type == "vector":
            if isinstance(query, str):
                if not self.embedder:
                    raise ValueError("KhÃ´ng cÃ³ embedder Ä‘á»ƒ vector hÃ³a query.")
                query = self.embedder.get_embedding(query)

            response = collection.query.near_vector(
                near_vector=query, limit=limit, return_metadata=["distance"]
            )
            results = []
            for obj in response.objects:
                distance = getattr(obj.metadata, "distance", None)
                score = 1 - distance if distance is not None else None
                results.append({"uuid": str(obj.uuid), "properties": obj.properties, "score": score, "distance": distance })
            return results

        elif search_type == "bm25":
            response = collection.query.bm25(
                query=query,
                query_properties=properties,
                limit=limit,
                return_metadata=MetadataQuery(score=True)
            )
            return [{"uuid": str(obj.uuid), "properties": obj.properties, "score": getattr(obj.metadata, "score", None)} for obj in response.objects]

        else:
            raise ValueError(f"Loáº¡i tÃ¬m kiáº¿m '{search_type}' khÃ´ng Ä‘Æ°á»£c há»— trá»£.")

    def hybrid_search(
        self,
        collection_name: str,
        query: str,
        alpha: float,
        limit: int = 50,
        properties: List[str] = ["title", "abstract", "keywords", "text"]
    ) -> List[Dict[str, Any]]:
        """
        Thá»±c hiá»‡n tÃ¬m kiáº¿m BM25 vÃ  Vector riÃªng biá»‡t, sau Ä‘Ã³ káº¿t há»£p Ä‘iá»ƒm sá»‘
        theo logic tÃ¹y chá»‰nh (chuáº©n hÃ³a BM25 vÃ  dÃ¹ng trá»ng sá»‘ alpha).
        ÄÃ¢y lÃ  phiÃªn báº£n Ä‘Ã³ng gÃ³i cá»§a logic cÅ© trong rag_pipeline.
        """
        # 1. Thá»±c hiá»‡n cáº£ hai loáº¡i tÃ¬m kiáº¿m
        try:
            hits_bm25 = self.search(collection_name, query, "bm25", limit, properties)
        except Exception:
            hits_bm25 = []

        try:
            hits_vec = self.search(collection_name, query, "vector", limit, properties)
        except Exception:
            hits_vec = []

        # 2. Táº­p há»£p vÃ  khá»­ trÃ¹ng láº·p káº¿t quáº£
        candidates: Dict[str, Dict[str, Any]] = {}
        for h in hits_bm25 + hits_vec:
            doc_id = h.get("uuid")
            if not doc_id:
                continue

            existing = candidates.get(doc_id)
            if not existing:
                candidates[doc_id] = {
                    "id": doc_id,
                    "properties": h.get("properties", {}),
                    "bm25_score": 0.0,
                    "vector_score": 0.0,
                }
            
            # Cáº­p nháº­t Ä‘iá»ƒm sá»‘ cao nháº¥t cho tá»«ng loáº¡i
            # Giáº£ Ä‘á»‹nh h['score'] lÃ  bm25_score cho hits_bm25 vÃ  vector_score cho hits_vec
            if "distance" in h: # ÄÃ¢y lÃ  káº¿t quáº£ vector search
                 vec_score = 1 - h["distance"] if h.get("distance") is not None else 0.0
                 candidates[doc_id]["vector_score"] = max(candidates[doc_id]["vector_score"], vec_score)
            else: # ÄÃ¢y lÃ  káº¿t quáº£ bm25
                 bm25_score = h.get("score") or 0.0
                 candidates[doc_id]["bm25_score"] = max(candidates[doc_id]["bm25_score"], bm25_score)

        if not candidates:
            return []

        # 3. TÃ­nh toÃ¡n Ä‘iá»ƒm káº¿t há»£p (logic y há»‡t code cÅ©)
        all_bm25_scores = [d["bm25_score"] for d in candidates.values() if d["bm25_score"] > 0]
        max_bm25 = max(all_bm25_scores) if all_bm25_scores else 0

        for doc in candidates.values():
            bm25_score = doc.get("bm25_score", 0.0)
            vector_score = doc.get("vector_score", 0.0)
            
            # Chuáº©n hÃ³a BM25
            bm25_norm = (bm25_score / max_bm25) if max_bm25 > 0 else 0.0
            
            # Káº¿t há»£p Ä‘iá»ƒm
            combined_score = alpha * vector_score + (1 - alpha) * bm25_norm
            doc["combined_score"] = combined_score

        # 4. Sáº¯p xáº¿p vÃ  tráº£ vá» káº¿t quáº£
        sorted_results = sorted(candidates.values(), key=lambda x: x["combined_score"], reverse=True)
        return sorted_results



def test():
    """Kiá»ƒm tra search (vector + BM25) trÃªn dá»¯ liá»‡u nhá»."""
    from datetime import timezone
    from rag_retrieval.model.ollama_models import OllamaEmbedder
    from dotenv import load_dotenv

    load_dotenv()
    embedder = OllamaEmbedder()

    with WeaviateManager(embedder=embedder) as manager:
        collection_name = "Papers"
        properties = [
            Property(name="title", data_type=DataType.TEXT),
            Property(name="abstract", data_type=DataType.TEXT),
            Property(name="keywords", data_type=DataType.TEXT_ARRAY),
            Property(name="text", data_type=DataType.TEXT),
            Property(name="created_date", data_type=DataType.DATE),
        ]
        manager.create_collection(name=collection_name, properties=properties, force_recreate=True)

        # ThÃªm vÃ i bÃ i thá»­
        papers = [
            {
                "title": "Attention Is All You Need",
                "abstract": "This paper introduces the Transformer architecture...",
                "keywords": ["AI", "Transformer"],
                "text": "Full text about the Transformer architecture...",
                "created_date": datetime(2017, 6, 12, tzinfo=timezone.utc),
            },
            {
                "title": "BERT: Pre-training of Deep Bidirectional Transformers",
                "abstract": "BERT is designed to pre-train deep bidirectional representations...",
                "keywords": ["AI", "NLP", "BERT"],
                "text": "Full text about BERT...",
                "created_date": datetime(2018, 10, 11, tzinfo=timezone.utc),
            },
        ]

        for paper in papers:
            manager.add(
                collection_name=collection_name,
                title=paper["title"],
                abstract=paper["abstract"],
                keywords=paper["keywords"],
                text=paper["text"],
                created_date=paper["created_date"],
            )

        # ============================
        # 1ï¸âƒ£ Vector search
        # ============================
        query_text = "What is a Transformer architecture?"
        search_results = manager.search(collection_name, query=query_text, search_type="vector", limit=2)

        print(f"\nğŸ” Vector search cho: '{query_text}'")
        for res in search_results:
            print(f"  - {res['properties'].get('title')} (Score: {res['score']})")

        # ============================
        # 2ï¸âƒ£ BM25 search
        # ============================
        query_text = "Transformer architecture"
        search_results = manager.search(collection_name, query=query_text, search_type="bm25", limit=2)

        print(f"\nğŸ” BM25 search cho: '{query_text}'")
        for res in search_results:
            print(f"  - {res['properties'].get('title')} (Score: {res['score']})")

    print("\nâœ… Test hoÃ n táº¥t.")


def gen():
    """
    Táº¡o dá»¯ liá»‡u máº«u Ä‘a dáº¡ng Ä‘á»ƒ kiá»ƒm tra há»‡ thá»‘ng RAG.
    HÃ m nÃ y sáº½ xÃ³a collection cÅ© (náº¿u cÃ³) vÃ  táº¡o láº¡i tá»« Ä‘áº§u.
    """
    from datetime import timezone
    # Giáº£ Ä‘á»‹nh báº¡n Ä‘Ã£ cÃ³ embedder trong thÆ° má»¥c model vÃ  Ä‘Ã£ cÃ i dotenv
    from rag_retrieval.model.wrapper.embedder_ollama import OllamaEmbedder
    from dotenv import load_dotenv
    import os

    print("--- Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh táº¡o dá»¯ liá»‡u thá»­ nghiá»‡m ---")

    # Táº£i biáº¿n mÃ´i trÆ°á»ng (vÃ­ dá»¥: OLLAMA_BASE_URL) tá»« file .env
    load_dotenv()
    
    try:
        # Khá»Ÿi táº¡o embedder
        # HÃ£y cháº¯c cháº¯n ráº±ng model embed cá»§a báº¡n (vÃ­ dá»¥: nomic-embed-text) Ä‘Ã£ Ä‘Æ°á»£c pull vá» Ollama
        embedder = OllamaEmbedder(model_name=os.getenv("EMBED_MODEL", "nomic-embed-text"))
        print(f"ÄÃ£ khá»Ÿi táº¡o Embedder vá»›i model '{embedder.model_name}'")
    except Exception as e:
        print(f"Lá»—i khi khá»Ÿi táº¡o Embedder: {e}")
        print("Vui lÃ²ng Ä‘áº£m báº£o Ollama Ä‘ang cháº¡y vÃ  Ä‘Ã£ pull model embedding.")
        return

    # Dá»¯ liá»‡u máº«u Ä‘a dáº¡ng
    papers = [
        {
            "title": "Attention Is All You Need",
            "abstract": "The Transformer, based solely on attention mechanisms, is introduced. This new architecture eschews recurrence and convolutions entirely.",
            "keywords": ["AI", "Transformer", "NLP", "Attention Mechanism"],
            "text": "The full text explains the encoder-decoder structure, scaled dot-product attention, multi-head attention, and positional encodings which are fundamental to the Transformer model's success in sequence transduction tasks.",
            "created_date": datetime(2017, 6, 12, tzinfo=timezone.utc),
        },
        {
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "abstract": "BERT stands for Bidirectional Encoder Representations from Transformers. It is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context.",
            "keywords": ["AI", "NLP", "BERT", "Language Model"],
            "text": "This paper demonstrates that BERT achieves state-of-the-art results on a wide array of natural language processing tasks. The core innovation is the application of bidirectional training of Transformers, which was not possible with previous language models.",
            "created_date": datetime(2018, 10, 11, tzinfo=timezone.utc),
        },
        {
            "title": "The Impact of Climate Change on Global Food Security",
            "abstract": "This study analyzes the effects of rising global temperatures and changing precipitation patterns on agricultural yields worldwide.",
            "keywords": ["Climate Change", "Agriculture", "Food Security", "Environment"],
            "text": "Detailed analysis shows that staple crops like wheat, rice, and maize are particularly vulnerable to climate stressors. The paper discusses mitigation strategies, including developing climate-resilient crops and improving water management techniques to ensure future food security.",
            "created_date": datetime(2021, 3, 22, tzinfo=timezone.utc),
        },
        {
            "title": "CRISPR-Cas9: A Revolutionary Tool for Genome Editing",
            "abstract": "An overview of the CRISPR-Cas9 system, a powerful and precise tool for making changes to the DNA of organisms.",
            "keywords": ["Biology", "Genetics", "CRISPR", "Biotechnology"],
            "text": "The text delves into the mechanisms of CRISPR-Cas9, its applications in treating genetic disorders, agricultural advancements, and the ethical considerations surrounding its use in humans. It compares CRISPR to older gene-editing techniques like ZFNs and TALENs.",
            "created_date": datetime(2014, 1, 15, tzinfo=timezone.utc),
        },
        {
            "title": "Renewable Energy Sources and Grid Integration Challenges",
            "abstract": "This paper explores the technical challenges of integrating variable renewable energy sources like solar and wind into traditional power grids.",
            "keywords": ["Energy", "Renewable Energy", "Solar Power", "Wind Power", "Power Grid"],
            "text": "The primary challenges discussed are intermittency and grid stability. Solutions like energy storage systems (batteries), smart grid technologies, and improved forecasting models are evaluated for their effectiveness in creating a reliable and sustainable energy future.",
            "created_date": datetime(2020, 8, 5, tzinfo=timezone.utc),
        },
         {
            "title": "A Study on Deep Reinforcement Learning for Robotic Manipulation",
            "abstract": "This work presents a novel deep reinforcement learning (DRL) framework that enables robots to learn complex manipulation skills from raw pixel inputs.",
            "keywords": ["AI", "Robotics", "Reinforcement Learning", "Deep Learning"],
            "text": "The framework utilizes a combination of convolutional neural networks for vision and recurrent neural networks for temporal understanding. We demonstrate its effectiveness on tasks such as object grasping and stacking, showing superior performance compared to traditional control methods.",
            "created_date": datetime(2019, 5, 30, tzinfo=timezone.utc),
        },
    ]

    # Sá»­ dá»¥ng WeaviateManager Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c thao tÃ¡c
    try:
        with WeaviateManager(embedder=embedder) as manager:
            collection_name = "Papers"
            properties = [
                Property(name="title", data_type=DataType.TEXT),
                Property(name="abstract", data_type=DataType.TEXT),
                Property(name="keywords", data_type=DataType.TEXT_ARRAY),
                Property(name="text", data_type=DataType.TEXT),
                Property(name="created_date", data_type=DataType.DATE),
            ]
            
            print(f"\n[1/3] Äang táº¡o collection '{collection_name}' (sáº½ xÃ³a náº¿u Ä‘Ã£ tá»“n táº¡i)...")
            manager.create_collection(name=collection_name, properties=properties, force_recreate=True)
            print(f"âœ… Collection '{collection_name}' Ä‘Ã£ Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng.")

            print(f"\n[2/3] Äang thÃªm {len(papers)} tÃ i liá»‡u vÃ o collection...")
            for i, paper in enumerate(papers):
                manager.add(
                    collection_name=collection_name,
                    title=paper["title"],
                    abstract=paper["abstract"],
                    keywords=paper["keywords"],
                    text=paper["text"],
                    created_date=paper["created_date"],
                )
                print(f"  -> ÄÃ£ thÃªm tÃ i liá»‡u {i+1}/{len(papers)}: '{paper['title']}'")
            
            print("âœ… ThÃªm dá»¯ liá»‡u hoÃ n táº¥t.")

            print("\n[3/3] Kiá»ƒm tra nhanh báº±ng má»™t truy váº¥n tÃ¬m kiáº¿m...")
            query_text = "What are the challenges of renewable energy?"
            search_results = manager.search(collection_name, query=query_text, search_type="vector", limit=2)
            
            print(f"\nğŸ” Káº¿t quáº£ tÃ¬m kiáº¿m vector cho: '{query_text}'")
            if search_results:
                for res in search_results:
                    print(f"  - TiÃªu Ä‘á»: {res['properties'].get('title')} (Score: {res['score']:.4f})")
            else:
                print("  - KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£.")

    except ConnectionError as ce:
        print(f"\nLá»–I Káº¾T Ná»I: {ce}")
        print("Vui lÃ²ng Ä‘áº£m báº£o Weaviate Ä‘ang cháº¡y vÃ  cáº¥u hÃ¬nh host/port lÃ  chÃ­nh xÃ¡c.")
    except Exception as e:
        print(f"\nÄÃ£ xáº£y ra lá»—i khÃ´ng mong muá»‘n: {e}")

    print("\n--- âœ… QuÃ¡ trÃ¬nh táº¡o dá»¯ liá»‡u Ä‘Ã£ hoÃ n táº¥t. ---")


if __name__ == "__main__":
    # Cháº¡y hÃ m nÃ y Ä‘á»ƒ báº¯t Ä‘áº§u táº¡o dá»¯ liá»‡u
    gen()